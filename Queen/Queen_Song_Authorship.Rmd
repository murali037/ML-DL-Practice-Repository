---
title: "Queenâ€™s Song Authorship"
author: "Murali Manohar"
date: "4/6/2019"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
---

```{r - reading the data}
library(readxl)
setwd("~/Documents/DATA MINING/Project")
Queen_raw <- read.csv("Queen_Lyrics.csv", stringsAsFactors = FALSE)
str(Queen_raw)
Queen_raw
```

```{r - grouping each song's lyrics as one observation}
library(dplyr)
    queen_grouped <-  group_by(Queen_raw,Song.no,Album.Name,Year,Song.Title,Class.label) %>% 
     summarise(lyrics = paste0(Lyrics, collapse = " ")) 
str(queen_grouped)
queen_grouped
```
```{r - changing the categorical variable to factor}
colnames(queen_grouped)[colnames(queen_grouped)=="Class.label"] <- "class"
queen_grouped$class <- factor(queen_grouped$class)
queen_grouped$class

summary(queen_grouped)
table(queen_grouped$class)
prop.table(table(queen_grouped$class))*100

#changing multibyte string encoding
queen_grouped$lyrics <- enc2utf8(queen_grouped$lyrics)


```
```{r - lemmatization}
library(textstem)

#test_lemma_string <- lemmatize_strings(queen_grouped$lyrics)
#test_lemma_string[1:5]

#test_lemma <- c("dogs went to the rivers","went","running", "eagles rivers")
#lemmatize_strings(test_lemma)

#before lemmatization = 2355 terms

#queen_grouped$lyrics <- lemmatize_strings(queen_grouped$lyrics)
#queen_grouped$lyrics[1:5]

```

```{r - creating the corpus - collection of text documents}
library(tm)

queen_corpus <- Corpus(VectorSource(queen_grouped$lyrics))
print(queen_corpus)
str(queen_corpus)
inspect(queen_corpus[1:5])

```

```{r - multibyte string test - to see if any error pops up}



find_offending_character <- function(x, maxStringLength=256){  
 print(x)
  for (c in 1:maxStringLength){
    offendingChar <- substr(x,c,c)
    #print(offendingChar) #uncomment if you want the indiv characters printed
    #the next character is the offending multibyte Character
  }    
}

lapply(queen_corpus, find_offending_character)



```

```{r - cleaning the text data}

queen_corpus <- tm_map(queen_corpus, tolower)
queen_corpus <- tm_map(queen_corpus, removeNumbers)
#queen_corpus <- tm_map(queen_corpus, removePunctuation)

#Not removing stop words since it doesnt improve accuracy
#stop_w <- c("the", "a", "and", "or", "but", "if")
#queen_corpus <- tm_map(queen_corpus, removeWords, stop_w)

queen_corpus <- tm_map(queen_corpus, stripWhitespace)

#remove punctuations
for(i in 1:97){
queen_corpus[[i]] = removePunctuation(queen_corpus[[i]], preserve_intra_word_contractions = TRUE,
                               preserve_intra_word_dashes = TRUE)
}


inspect(queen_corpus[1:5])
```



```{r - Document Term Matrix}

queen_dtm <- DocumentTermMatrix(queen_corpus)
queen_dtm
inspect(queen_dtm)

#lemmatization step was carried out before creating the corpus of documents
#Before lemmatizaion, no of words - 2355
#After lemmatization, no of words - 1915

#correction - later decided not to go forward with lemmatization after testing

```
```{r - wordcloud showing word frequency based on songwriter}

library(wordcloud)

par(mfrow=c(1,2))

freddy_mercury <- subset(queen_grouped, class == "FM")
brian_may <- subset(queen_grouped, class == "BM")


wordcloud(freddy_mercury$lyrics,min.freq = 10, colors = "RED", 
          scale = c(3,0.5), max.words = 60, random.order = FALSE)
wordcloud(brian_may$lyrics,min.freq = 10, colors = "Black", 
          scale = c(3,0.5), max.words = 60, random.order = FALSE)

```
```{r - initial classification approach - no of unique terms per document vs song length}

inspect(queen_dtm)
song_length <- rowSums(as.matrix(queen_dtm))  #song length 

#function for finding unique words
uniqueWords = function(d) {
  return(paste(unique(strsplit(d, " ")[[i]]), collapse = ' '))
}

queen_corpus_unique <- queen_corpus

for(i in 1:97)
{
queen_corpus_unique[[i]] <- tm_map(queen_corpus, content_transformer(uniqueWords))
}

queen_corpus_unique = tm_map(queen_corpus_unique, removePunctuation)
queen_corpus_unique = tm_map(queen_corpus_unique, removeWords, c("en\nlist", "\nlistlanguage"))
inspect(queen_corpus_unique[1:3])

queen_dtm_unique <- DocumentTermMatrix(queen_corpus_unique)
inspect(queen_dtm_unique)

unique_words <- rowSums(as.matrix(queen_dtm_unique[,]))


#Freddie Mercury song length and unique words - not used here
rowSums(as.matrix(queen_dtm[freddy_mercury$Song.no,]))
rowSums(as.matrix(queen_dtm_unique[freddy_mercury$Song.no,]))

#Brian May song length and unique words - not used here
rowSums(as.matrix(queen_dtm[brian_may$Song.no,]))
rowSums(as.matrix(queen_dtm_unique[brian_may$Song.no,]))


song_length
unique_words

plot(song_length, unique_words, pch = ifelse(queen_grouped$class == "BM", 1, 4), col = ifelse(queen_grouped$class == "BM", "blue", "red"))

legend(x=40,y=152,c("Brian May","Freddie Mercury"),cex=.8,col=c("blue","red"),pch=c(1,4))




```
```{r - design matrix}

#class label vector 

y <- factor(queen_grouped$class)
y

X <- as.data.frame(as.matrix(queen_dtm))

X


```
```{r - (1) K means clustering Algorithm}

y <- factor(queen_grouped$class)
y

X <- as.data.frame(as.matrix(queen_dtm))

X


#dist.matrix <- dist(tdm.tfidf.matrix, method = "cosine")

Kmeans_model <- kmeans(queen_dtm, 2)
Kmeans_model$cluster <- factor(Kmeans_model$cluster)
Kmeans_model$cluster


y <- ifelse(y == "BM", 1, 2)

table(Kmeans_model$cluster,y)

KM_Fac <- factor(Kmeans_model$cluster)
KM_y <- factor(y)
confusionMatrix(KM_Fac,KM_y)
Accuracy_Kmeans <- (39+16)/97
print('Highest Accuracy achieved using Kmeans in 10 Iterations')
Accuracy_Kmeans*100  # Kmeans accuracy 53.6%
# is.na(queen_grouped$Album.Name) 
# queen_grouped$Album.Name[96] <- c("xyz")



#plotting
library(cluster)
a <- dist(queen_dtm, method = "euclidean")
clusplot(as.matrix(a),Kmeans_model$cluster, color = T, shade = T, labels = 0, lines = 0)


```

```{r - (2) K- Nearest Neighbour Algorithm}
library(class)
library(caret)

y <- factor(queen_grouped$class)
y

X <- as.data.frame(as.matrix(queen_dtm))

X

c_label <- queen_grouped$class   #class label
X <- as.data.frame(as.matrix(queen_dtm))   #data set for LOOCV


# train test split - 70 - 30
Knn_train <- X[1:68,]
Knn_test <- X[69:97,]

y_pred_70_30 <- knn(train = Knn_train, test = Knn_test, cl = c_label[1:68], k=3)

#CrossTable(y_pred_70_30,c_label[69:97], prop.chisq = FALSE, prop.t = FALSE, dnn = c('Predicted', 'Actual'))
#Accuracy_Knn <- (10+8)/29   #62%
#Accuracy_Knn

cm <- confusionMatrix(y_pred_70_30,c_label[69:97])
cm$overall['Accuracy']*100
cm


#leave one out cross validation
cm.knn.acc.recorder <- as.data.frame(queen_grouped$class)
cm.knn.acc.recorder$predicted <- queen_grouped$class
cm.knn.acc.recorder$accuracy <- 0
cm.knn.acc.recorder$accuracy <- as.numeric(cm.knn.acc.recorder$accuracy)
cm.accuracy_knn <- c(0)
for(i in 1:97) {
  x_i <- X[-i,]
  y_i <- X[i,]
  y_pred_knn_Loocv = knn(train = x_i, test = y_i, cl = c_label[-i], k=5)
  cm_Loocv_knn <- confusionMatrix(y_pred_knn_Loocv,c_label[i])
  cm.knn.acc.recorder[i,2] <- y_pred_knn_Loocv
  cm.knn.acc.recorder[i,3] <-  cm_Loocv_knn$overall['Accuracy']
}

cm.accuracy_knn <- mean(cm.knn.acc.recorder$accuracy)*100
cm.accuracy_knn  #62.88%
cm.knn.acc.recorder


```

```{r -(3) Naive Bayes Algorithm}

y <- factor(queen_grouped$class)
y

X <- as.data.frame(as.matrix(queen_dtm))

X

library(e1071)
 convert_counts <- function(x) {
    x <- ifelse(x > 0, 1, 0)
    x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
    return(x)
 }

 
# train test split - 70 - 30

NB_train <- X[1:68,]
NB_train <- apply(NB_train, MARGIN = 2, convert_counts)
NB_test <- X[69:97,]
NB_test <- apply(NB_test, MARGIN = 2, convert_counts)

NB_model <- naiveBayes(NB_train,c_label[1:68], laplace=0)
NB_predict <- predict(NB_model, NB_test, type = "class" )

cm_NB <- confusionMatrix(y_pred_70_30,c_label[69:97])
cm_NB$overall['Accuracy']
cm_NB #62%

#leave one out cross validation
cm.NB.acc.recorder <- as.data.frame(queen_grouped$class)
cm.NB.acc.recorder$predicted <- queen_grouped$class
cm.NB.acc.recorder$accuracy <- 0
cm.NB.acc.recorder$accuracy <- as.numeric(cm.NB.acc.recorder$accuracy)
cm.accuracy_NB <- c(0)
for(i in 1:97) {
  x_i <- X[-i,]
  x_i <- apply(x_i, MARGIN = 2, convert_counts)
  y_i <- X[i,]
  y_i <- apply(y_i, MARGIN = 2, convert_counts)
  y_i <- t(as.matrix(y_i))
  
  NB_model_Loocv <- naiveBayes(x_i,c_label[-i], laplace=0)
  NB_predict_Loocv <- predict(NB_model_Loocv, y_i, type = "class" )
  
  cm_Loocv_NB <- confusionMatrix(NB_predict_Loocv,c_label[i])
  cm.NB.acc.recorder[i,2] <- NB_predict_Loocv
  cm.NB.acc.recorder[i,3] <-  cm_Loocv_NB$overall['Accuracy']
}

cm.accuracy_NB <- mean(cm.NB.acc.recorder$accuracy)*100
cm.accuracy_NB #61.85%
cm.NB.acc.recorder



```
```{r - (4) Logistic Regression}

y <- factor(queen_grouped$class)
y

X <- as.data.frame(as.matrix(queen_dtm))

X

library(caTools)


LR_train <- X[1:68,]
LR_train$cl <- y[1:68]
LR_train$cl <- factor(LR_train$cl)

LR_test <- X[69:97,]

LR_model <- glm(formula = cl~., family = binomial, data = LR_train)
#summary(LR_model)
LR_prob <- predict.glm(LR_model, type = "response", newdata = LR_test)

y_factor <- factor(y)
contrasts(y_factor) #BM = 0, FM=1
LR_predict <- rep("BM", nrow(LR_test))
LR_predict[LR_prob>.5] <- "FM"
LR_predict <- factor(LR_predict)

cm_LR <- confusionMatrix(LR_predict,c_label[69:97])
cm_LR$overall['Accuracy']*100  #62.06%
cm_LR



#leave one out cross validation
cm.logR.acc.recorder <- as.data.frame(queen_grouped$class)
cm.logR.acc.recorder$predicted <- queen_grouped$class
cm.logR.acc.recorder$accuracy <- 0
cm.logR.acc.recorder$predicted_probability <- 0
cm.logR.acc.recorder$accuracy <- as.numeric(cm.logR.acc.recorder$accuracy)
cm.accuracy_logR <- c(0)
for(i in 1:97) {
  
  x_i <- X
  x_i$cl <- y 
  x_i$cl <- factor(x_i$cl)
  x_i <- x_i[-i,]
  
  y_i <- X[i,]
  
  logR_model_Loocv <- glm(formula = cl~., family = binomial, data = x_i)
  logR_prob_Loocv <- predict.glm(logR_model_Loocv, type = "response", newdata = y_i)
  
  logR_predict_Loocv <- rep("BM", nrow(y_i))
 logR_predict_Loocv[logR_prob_Loocv>.5] <- "FM"
 logR_predict_Loocv <- factor(logR_predict_Loocv)
  
  
  cm_Loocv_logR <- confusionMatrix(logR_predict_Loocv,c_label[i])
  cm.logR.acc.recorder[i,2] <- logR_predict_Loocv
  cm.logR.acc.recorder[i,3] <-  cm_Loocv_logR$overall['Accuracy']
  cm.logR.acc.recorder[i,4] <- logR_prob_Loocv
}

cm.accuracy_logR <- mean(cm.logR.acc.recorder$accuracy)*100
cm.accuracy_logR #53.60%
cm.logR.acc.recorder


```
```{r - (5) Support Vector Machines}

y <- factor(queen_grouped$class)
y

X <- as.data.frame(as.matrix(queen_dtm))

X

library(e1071)

SVM_train <- X[1:68,]
SVM_train$cl <- y[1:68]
SVM_train$cl <- factor(SVM_train$cl)

SVM_test <- X[69:97,]

SVM_model <- svm(cl~., data = SVM_train, type = 'C-classification', kernal = 'linear')

SVM_predict <- predict(SVM_model, newdata = SVM_test)

cm_SVM <- confusionMatrix(SVM_predict,c_label[69:97])
cm_SVM$overall['Accuracy']*100   #41.37
cm_SVM

#leave one out cross validation
cm.SVM.acc.recorder <- as.data.frame(queen_grouped$class)
cm.SVM.acc.recorder$predicted <- queen_grouped$class
cm.SVM.acc.recorder$accuracy <- 0
cm.SVM.acc.recorder$accuracy <- as.numeric(cm.SVM.acc.recorder$accuracy)
cm.accuracy_SVM <- c(0)
for(i in 1:97) {
 x_i <- X
  x_i$cl <- y 
  x_i$cl <- factor(x_i$cl)
  x_i <- x_i[-i,]
  
  y_i <- X[i,]
  
  SVM_model_Loocv <- svm(cl~., data = x_i, type = 'C-classification', kernal = 'polynomial')
  SVM_predict_Loocv <- predict(SVM_model_Loocv, newdata = y_i)
  
  cm_Loocv_SVM <- confusionMatrix(SVM_predict_Loocv,c_label[i])
  cm.SVM.acc.recorder[i,2] <- SVM_predict_Loocv
  cm.SVM.acc.recorder[i,3] <-  cm_Loocv_SVM$overall['Accuracy']
}

cm.accuracy_SVM <- mean(cm.SVM.acc.recorder$accuracy)*100
cm.accuracy_SVM  #58.76%
cm.SVM.acc.recorder

```
```{r}
# #Visualising the Training set results
# library(ElemStatLearn)
# set = SVM_train
# X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
# X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
# grid_set = expand.grid(X1, X2)
# colnames(grid_set) = c('Age', 'EstimatedSalary')
# y_grid = predict(SVM_model, newdata = grid_set)
# plot(set[, -3],
#      main = 'SVM (Training set)',
#      xlab = 'Age', ylab = 'Estimated Salary',
#      xlim = range(X1), ylim = range(X2))
# contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
# points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
# points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# 
# # Visualising the Test set results
# library(ElemStatLearn)
# set = test_set
# X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
# X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
# grid_set = expand.grid(X1, X2)
# colnames(grid_set) = c('Age', 'EstimatedSalary')
# y_grid = predict(classifier, newdata = grid_set)
# plot(set[, -3], main = 'SVM (Test set)',
#      xlab = 'Age', ylab = 'Estimated Salary',
#      xlim = range(X1), ylim = range(X2))
# contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
# points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
# points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))


```
